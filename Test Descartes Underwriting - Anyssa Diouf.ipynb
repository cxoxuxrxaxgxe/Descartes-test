{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descartes Underwriting Test : Auto Insurance\n",
    "Anyssa Diouf \n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The goal of this project is to predict whether an auto insurer will have to pay claims (the target TARGET_FLAG), and predict their amounts (denoted by the target TARGET_AMT). \n",
    "\n",
    "* This code returns the value of the performance of the algorithms tested and generates a csv file with the predictions. The values of the performance of the algorithms tested are also presented.\n",
    "\n",
    "* I didn't have the time to look at the features importance of the model I used. I would have done it using the SHAP package, as in [here](https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector, make_column_transformer\n",
    "from sklearn.metrics import log_loss, make_scorer, matthews_corrcoef, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from xgboost import XGBClassifier, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "df_test = pd.read_csv(os.path.join(path_data, \"test_auto.csv\"), index_col='INDEX')\n",
    "df_train = pd.read_csv(os.path.join(path_data, \"train_auto.csv\"), index_col='INDEX')\n",
    "\n",
    "mean_auto = pd.read_csv(os.path.join(path_data, \"MEAN_AUTO.csv\"))\n",
    "shell_auto = pd.read_csv(os.path.join(path_data, \"SHELL_AUTO.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see that indexes (from the INDEX column) in mean_auto and shell_auto only match the ones in test_auto, the test dataset. As they do not match the INDEX column of the training dataset, we will not use those features. \n",
    "In the following, only the variables in df_train will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>INDEX</th>\n",
       "      <th>9471</th>\n",
       "      <th>7153</th>\n",
       "      <th>6566</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>INCOME</th>\n",
       "      <td>$0</td>\n",
       "      <td>$10,359</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOME_VAL</th>\n",
       "      <td>$0</td>\n",
       "      <td>$75,321</td>\n",
       "      <td>$367,206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLUEBOOK</th>\n",
       "      <td>$7,270</td>\n",
       "      <td>$16,570</td>\n",
       "      <td>$17,580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLDCLAIM</th>\n",
       "      <td>$2,280</td>\n",
       "      <td>$0</td>\n",
       "      <td>$43,663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "INDEX       9471     7153      6566\n",
       "INCOME        $0  $10,359       NaN\n",
       "HOME_VAL      $0  $75,321  $367,206\n",
       "BLUEBOOK  $7,270  $16,570   $17,580\n",
       "OLDCLAIM  $2,280       $0   $43,663"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['INCOME', 'HOME_VAL', 'BLUEBOOK', 'OLDCLAIM']].sample(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning money amounts strings to floats\n",
    "def floatmoney(s): \n",
    "    if type(s) == str:\n",
    "        return float(s.replace('$','').replace(',',''))\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "def preprocess(df):\n",
    "    dollar_vars = ['INCOME', 'HOME_VAL', 'BLUEBOOK', 'OLDCLAIM']\n",
    "    for var in dollar_vars:\n",
    "        df[var] = [floatmoney(s) for s in df[var].tolist()]\n",
    "\n",
    "    # Turning NaN's to a character equivalent for the Ordinal Encoder that we'll later use\n",
    "    for var in df.select_dtypes(exclude='number').columns: \n",
    "        df[var] = df[var].fillna('unknown')\n",
    "    return df\n",
    "\n",
    "df_train = preprocess(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>INDEX</th>\n",
       "      <th>6721</th>\n",
       "      <th>6124</th>\n",
       "      <th>9636</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>INCOME</th>\n",
       "      <td>25535.0</td>\n",
       "      <td>35120.0</td>\n",
       "      <td>44949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOME_VAL</th>\n",
       "      <td>99326.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLUEBOOK</th>\n",
       "      <td>18270.0</td>\n",
       "      <td>17700.0</td>\n",
       "      <td>15520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLDCLAIM</th>\n",
       "      <td>30146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "INDEX        6721     6124      9636\n",
       "INCOME    25535.0  35120.0   44949.0\n",
       "HOME_VAL  99326.0      0.0  185547.0\n",
       "BLUEBOOK  18270.0  17700.0   15520.0\n",
       "OLDCLAIM  30146.0      0.0       0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['INCOME', 'HOME_VAL', 'BLUEBOOK', 'OLDCLAIM']].sample(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the XGBoost model: it is notoriously performant and can handle missing values/NaN's relevantly. <br>\n",
    "We first start by defining the estimators and creating a pipeline for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding strings \n",
    "ordinal_encoder = make_column_transformer(\n",
    "    (OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan),\n",
    "     make_column_selector(dtype_exclude='number')),\n",
    "    remainder='passthrough')\n",
    "\n",
    "# Use of XGBoost to classify TARGET_FLAG and regress TARGET_AMT\n",
    "xgb_model_clf = XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model_reg = XGBRegressor(use_label_encoder=False)\n",
    "\n",
    "# Pipeline\n",
    "pipe_clf = make_pipeline(ordinal_encoder, xgb_model_clf)\n",
    "pipe_reg = make_pipeline(ordinal_encoder, xgb_model_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train each pipeline. We use a k-fold cross validation on the training dataset to (k=5) to get a general idea of the model performance. We use the Matthews correlation coefficient as a  metric for the classification, and the root of the mean squared error/RMSE for the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining explainatory variables and targets \n",
    "X = df_train.drop(columns=['TARGET_FLAG', 'TARGET_AMT'])\n",
    "y_clf = df_train['TARGET_FLAG']\n",
    "y_reg = df_train['TARGET_AMT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37015116, 0.43846707, 0.37436551, 0.39569546, 0.37427354])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation for the classification\n",
    "cross_val_score(estimator=pipe_clf, \n",
    "                X=X, \n",
    "                y=y_clf, \n",
    "                cv=5, \n",
    "                scoring=make_scorer(matthews_corrcoef, greater_is_better=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4467.5149588 , 5233.98837826, 4111.70002891, 5014.40489307,\n",
       "       5730.6166709 ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation for the regression\n",
    "scores_reg = cross_val_score(estimator=pipe_reg, \n",
    "                X=X, \n",
    "                y=y_reg, \n",
    "                cv=5, \n",
    "                scoring=make_scorer(mean_squared_error, greater_is_better=False))\n",
    "np.sqrt(-scores_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scores aren't the best. Had I had more time, I would have try to improve them by optimising hyperparameters for example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "pipe_clf.fit(X, y_clf)\n",
    "pipe_reg.fit(X, y_reg);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>INDEX</th>\n",
       "      <th>5908</th>\n",
       "      <th>560</th>\n",
       "      <th>3013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>INCOME</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3865.0</td>\n",
       "      <td>52411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOME_VAL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLUEBOOK</th>\n",
       "      <td>11310.0</td>\n",
       "      <td>16600.0</td>\n",
       "      <td>11340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLDCLAIM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6089.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "INDEX        5908     560       3013\n",
       "INCOME        NaN   3865.0   52411.0\n",
       "HOME_VAL      0.0      0.0  158113.0\n",
       "BLUEBOOK  11310.0  16600.0   11340.0\n",
       "OLDCLAIM      0.0   6089.0       0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing \n",
    "df_test = preprocess(df_test)\n",
    "df_test[['INCOME', 'HOME_VAL', 'BLUEBOOK', 'OLDCLAIM']].sample(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining explanatory variables and targets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(columns=['TARGET_FLAG', 'TARGET_AMT'])\n",
    "\n",
    "y_flag = pipe_clf.predict(X_test)\n",
    "y_amount = pipe_reg.predict(X_test)*y_flag # y_flag is used as an indicator function (puts the amount to zero when needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET_FLAG</th>\n",
       "      <th>TARGET_AMT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>1</td>\n",
       "      <td>3040.458496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4863</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TARGET_FLAG   TARGET_AMT\n",
       "INDEX                          \n",
       "3246             1  3040.458496\n",
       "731              0     0.000000\n",
       "4863             0     0.000000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(zip(y_flag, y_amount), columns=['TARGET_FLAG', 'TARGET_AMT'], index=X_test.index)\n",
    "df_results.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting as csv :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"data/predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
